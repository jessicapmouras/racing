{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'organizing_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e673c2f08c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnbimporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0morganizing_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'organizing_data'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "import nbimporter\n",
    "from organizing_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv data \n",
    "races = pd.read_csv('src/races.csv')\n",
    "runs = pd.read_csv('src/runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in 0's for NaN values in times for non-existent portions of race\n",
    "runs['time4'].fillna(0, inplace=True)\n",
    "runs['time5'].fillna(0, inplace=True)\n",
    "runs['time6'].fillna(0, inplace=True)\n",
    "\n",
    "#check to see if fill in worked\n",
    "runs.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#narrow down focus of columns/ features from run data desired to analyze\n",
    "\n",
    "runs_data = runs[['race_id', 'won', 'horse_age', 'horse_country', 'horse_type', 'horse_rating',\n",
    "       'horse_gear', 'declared_weight', 'actual_weight', 'draw', 'win_odds',\n",
    "       'place_odds','time1', 'time2', 'time3', 'time4', 'time5', 'time6', 'horse_id']]\n",
    "# runs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#narrow down focus of columns/ features from races data desired to analyze\n",
    "races_data = races[['race_id', 'date', 'venue', 'race_no', 'config', 'surface', 'distance',\n",
    "       'going', 'horse_ratings', 'prize', 'race_class']]\n",
    "# races_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two datasets based on race_id column\n",
    "df = pd.merge(runs_data, races_data)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for total_time\n",
    "\n",
    "df['total_time'] = (df['time1'] + df['time2'] + df['time3'])\n",
    "# df['total_time'].head(10)\n",
    "\n",
    "#add avg time per section column\n",
    "df['avg_time'] = (df['time1'] +df['time2'] +df['time3'])/3\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update DataFrame for jockey weight class column calculated\n",
    "df[\"weight_class\"] = df.apply(lambda row: group_jockweight(row), axis=1)\n",
    "df[[\"actual_weight\",\"weight_class\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update DataFrame for horse weight class column calculated\n",
    "df[\"horseweight_class\"] = df.apply(lambda row: group_horseweight(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the MAJOR outliers\n",
    "df = df[(df['total_time'] < 90)]\n",
    "\n",
    "total_time_df = df[(df['total_time'] < 90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create dirt and turf DataFrames and remove outliers\n",
    "# dirt_df = df[df['surface'] == 1]\n",
    "# turf_df = df[df['surface'] == 0]\n",
    "# turf_df = df[df['total_time'] < 90]\n",
    "\n",
    "# # create Pandas Series for Turf and Dirt\n",
    "# dirt_time_df = dirt_df['total_time']\n",
    "# turf_time_df = turf_df['total_time']\n",
    "\n",
    "# #create data array for dirt avg time\n",
    "# dirt_time = np.array(dirt_time_df)\n",
    "# #create data array for turf avg time\n",
    "# turf_time = np.array(turf_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe for new sub-population_races of 1200m\n",
    "total_time_dist1_df = df[(df['distance'] == 1200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas drop columns using list of column names for heatmap\n",
    "total_time_dist1_df_clean = total_time_dist1_df.drop(['time4', 'time5', 'time6', 'surface', 'distance'], axis=1)\n",
    "total_time_dist1_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to take population into subsets based on total distance of race (1200 first distance)\n",
    "total_time_dist1_df = df[(df['distance'] == 1200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split between venues for hypothesis testing\n",
    "\n",
    "HV_time_dist1_df = total_time_dist1_df[(total_time_dist1_df['venue'] == 'HV')]\n",
    "ST_time_dist1_df = total_time_dist1_df[(total_time_dist1_df['venue'] == 'ST')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish the two population time arrays\n",
    "HV_time_dist = np.array(HV_time_dist1_df ['total_time'])\n",
    "ST_time_dist = np.array(ST_time_dist1_df ['total_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Sample Approximate Test of Population Means\n",
    "# Happy valley population\n",
    "\n",
    "HVpop_std = np.std(HV_time_dist)\n",
    "HVpop_mu = np.mean(HV_time_dist)\n",
    "HVpop_var = np.var(HV_time_dist)\n",
    "print(f\"The Happy Valley population std dev: {HVpop_std}, \\\n",
    "population variance: {HVpop_var},and population mean: {HVpop_mu}\")\n",
    "HVpopulation = stats.norm(HVpop_mu, HVpop_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Sample Approximate Test of Population Means\n",
    "# Shatin population\n",
    "\n",
    "STpop_std = np.std(ST_time_dist)\n",
    "STpop_mu = np.mean(ST_time_dist)\n",
    "STpop_var = np.var(ST_time_dist)\n",
    "print(f\"The Sha Tin population std dev: {STpop_std}, \\\n",
    "population variance: {STpop_var},and population mean: {STpop_mu}\")\n",
    "STpopulation = stats.norm(STpop_mu, STpop_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVsample = HVpopulation.rvs(1000)\n",
    "# STsample = STpopulation.rvs(1000)\n",
    "HVsample = np.random.choice(HV_time_dist, 200)\n",
    "STsample = np.random.choice(ST_time_dist, 200)\n",
    "print(type(HVsample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speeds: HV vs ST\n",
    "fig, ax = plt.subplots(1, figsize=(16, 3))\n",
    "\n",
    "ax.scatter(HVsample, \n",
    "           np.repeat(0, len(HVsample)) + \\\n",
    "           np.random.normal(0, 0.1, len(HVsample)), ## jitter\n",
    "           color = 'tan', s=45)\n",
    "ax.scatter(STsample, \n",
    "           np.repeat(1, len(STsample)) + \\\n",
    "           np.random.normal(0, 0.1, len(STsample)), \n",
    "           color = 'brown', s=45)\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels([\"HV\", \"ST\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welsh's t-test \n",
    "\n",
    "# def welch_test_statistic(sample_1, sample_2):\n",
    "#     numerator = np.mean(sample_1) - np.mean(sample_2)\n",
    "#     denominator_sq = (np.var(sample_1) / len(sample_1)) + \\\n",
    "#                         (np.var(sample_2) / len(sample_2))\n",
    "#     return numerator / np.sqrt(denominator_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistic = welch_test_statistic(STsample, HVsample)\n",
    "print(\"Welch Test Statistic: {:2.2f}\".format(test_statistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def welch_satterhwaithe_df(samp_1, samp_2):\n",
    "#     ss1 = len(samp_1)\n",
    "#     ss2 = len(samp_2)\n",
    "#     df = (((np.var(samp_1)/ss1 + np.var(samp_2)/ss2)**(2.0)) / \n",
    "#         ((np.var(samp_1)/ss1)**(2.0)/(ss1 - 1)\n",
    "#          + (np.var(samp_2)/ss2)**(2.0)/(ss2 - 1)))\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_free = welch_satterhwaithe_df(STsample, HVsample)\n",
    "print(f'Degrees of Freedom for Welch\\'s Test: {degrees_free}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Welch Stat Distrib\n",
    "x = np.linspace(-10, 10, num=250)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(16, 3))\n",
    "students = stats.t(degrees_free)\n",
    "ax.plot(x, students.pdf(x), linewidth=2, label=\"Degree of Freedom: {:2.2f}\".format(degrees_free))\n",
    "ax.legend()\n",
    "ax.set_title(\"Distribution of Welsh's Test Statistic Under the Null Hypothesis\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have enough evidence to conclude that one is better?\n",
    "p_value = students.cdf(test_statistic) + (1 - students.cdf(-test_statistic))\n",
    "print(\"p-value for different average times : {:2.14f}\".format(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have enough evidence to say HV turf track is \"less fast\"\n",
    "test_stat_better1 = welch_test_statistic(HVsample, STsample)\n",
    "\n",
    "p_value = 1 - students.cdf(test_stat_better1)\n",
    "print(\"p-value for HV time over distance greater than ST: {:2.14f}\".format(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if i do it again and limit it to track type 0 TURF ONLY\n",
    "# split between venues for hypothesis testing\n",
    "\n",
    "HV0_time_dist1_df = HV_time_dist1_df[(HV_time_dist1_df['surface'] == 0)]\n",
    "ST0_time_dist1_df = ST_time_dist1_df[(ST_time_dist1_df['surface'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish the two population time arrays for TURF ONLY\n",
    "HV0_time_dist = np.array(HV0_time_dist1_df ['total_time'])\n",
    "ST0_time_dist = np.array(ST0_time_dist1_df ['total_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Sample Approximate Test of Population Means\n",
    "# Happy valley population TURF ONLY\n",
    "\n",
    "HV0pop_std = np.std(HV0_time_dist)\n",
    "HV0pop_mu = np.mean(HV0_time_dist)\n",
    "HV0pop_var = np.var(HV0_time_dist)\n",
    "print(HV0pop_std, HV0pop_var, HV0pop_mu)\n",
    "HV0population = stats.norm(HV0pop_mu, HV0pop_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Sample Approximate Test of Population Means\n",
    "# Shatin population TURF ONLY\n",
    "\n",
    "ST0pop_std = np.std(ST0_time_dist)\n",
    "ST0pop_mu = np.mean(ST0_time_dist)\n",
    "ST0pop_var = np.var(ST0_time_dist)\n",
    "print(ST0pop_std, ST0pop_var, ST0pop_mu)\n",
    "ST0population = stats.norm(ST0pop_mu, ST0pop_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#large random sample over TURF ONLY\n",
    "np.random.seed(5)\n",
    "HV00sample = np.random.choice(HV0_time_dist, 8000)\n",
    "ST00sample = np.random.choice(ST0_time_dist, 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speeds: HV vs ST TURF ONLY POPULATION\n",
    "fig, ax = plt.subplots(1, figsize=(16, 3))\n",
    "\n",
    "ax.scatter(HV00sample, \n",
    "           np.repeat(0, len(HV00sample)) + \\\n",
    "           np.random.normal(0, 0.1, len(HV00sample)), ## jitter\n",
    "           label = 'Happy Valley', color = 'plum', s=45)\n",
    "ax.scatter(ST00sample, \n",
    "           np.repeat(1, len(ST00sample)) + \\\n",
    "           np.random.normal(0, 0.1, len(ST00sample)), \n",
    "           label = \"Sha Tin\", color = 'steelblue', s=45)\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels([\"HV Turf\", \"ST Turf\"], fontsize=14)\n",
    "ax.set_xlabel(\"Time (s)\", fontsize=14)\n",
    "ax.legend(loc = 'best')\n",
    "ax.set_title(\"Large Sample (8,000) 1200m Time Distributions\", fontsize=20)\n",
    "bbox_inches='tight';\n",
    "# plt.savefig('LargeSampleScatterHVSTTurf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small random sample TURF ONLY\n",
    "np.random.seed(5000)\n",
    "HV0sample = np.random.choice(HV0_time_dist, 100)\n",
    "ST0sample = np.random.choice(ST0_time_dist, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speeds: smaller sample HV vs ST TURF ONLY\n",
    "fig, ax = plt.subplots(1, figsize=(16, 3))\n",
    "\n",
    "ax.scatter(HV0sample, \n",
    "           np.repeat(0, len(HV0sample)) + \\\n",
    "           np.random.normal(0, 0.1, len(HV0sample)), ## jitter\n",
    "           label = 'Happy Valley', color = 'plum', s=45)\n",
    "ax.scatter(ST0sample, \n",
    "           np.repeat(1, len(ST0sample)) + \\\n",
    "           np.random.normal(0, 0.1, len(ST0sample)), \n",
    "           label = \"Sha Tin\", color = 'steelblue', s=45)\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels([\"HV Turf\", \"ST Turf\"], fontsize=12)\n",
    "ax.set_xlabel(\"Time (s)\", fontsize=12)\n",
    "ax.legend(loc = 'best')\n",
    "ax.set_title(\"Small Sample (100) 1200m Time Distributions\", fontsize=18);\n",
    "# plt.savefig('SampleScatterHVSTTurf.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smaller sample test stat\n",
    "test_statistic0 = welch_test_statistic(ST0sample, HV0sample)\n",
    "print(\"Welch Test Statistic: {:2.2f}\".format(test_statistic0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_free0 = welch_satterhwaithe_df(ST0sample, HV0sample)\n",
    "print(f'Degrees of Freedom for Welch\\'s Test: {degrees_free0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Welsh's Test Statistic Under the Null Hypothesis\n",
    "x = np.linspace(-6, 6, num=250)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(16, 4))\n",
    "students = stats.t(degrees_free0)\n",
    "ax.plot(x, students.pdf(x), linewidth=5, color = 'midnightblue', label=\"Degrees of Freedom: {:2.2f}\".format(degrees_free0))\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Welch Statistic\", fontsize=14)\n",
    "ax.set_title(\"Distribution of Welsh's Test Statistic Under the Null Hypothesis\", fontsize=20)\n",
    "plt.tight_layout();\n",
    "# plt.savefig('WelchStatDistribTurf.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller sample: Do we have enough evidence to conclude that one is better?\n",
    "p_value0 = students.cdf(test_statistic0) + (1 - students.cdf(-test_statistic0))\n",
    "print(\"p-value for different average times over turf : {:2.14f}\".format(p_value0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller sample: Do we have enough evidence to conclude that HV is less fast track?\n",
    "test_stat_better0 = welch_test_statistic(HV0sample, ST0sample)\n",
    "\n",
    "p0_value = 1 - students.cdf(test_stat_better0)\n",
    "print(\"p-value for HV time over distance greater than ST over turf: {:2.14f}\".format(p0_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate pvalue using stats ttest smaller sample\n",
    "stats.ttest_ind(ST0sample, HV0sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a two tailed ztest to run simulation of p values over time\n",
    "\n",
    "from statsmodels.stats import weightstats as stests\n",
    "\n",
    "result, pv = stests.ztest(ST0sample, x2=HV0sample, value=0,alternative='two-sided')\n",
    "print(result,pv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
